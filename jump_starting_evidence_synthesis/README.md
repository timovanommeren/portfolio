# Jump Starting Evidence Synthesis

This repository contains the code to reproduce the results of the simulation study *Jump Starting Evidence Synthesis: Initializing Active Learning Models for Systematic Reviews using LLM-generated Data*

In short, the contents of this repository allow for:
1. A full replication of the simulation and analysis in Python and R respectively,
2. A replication of the analysis only in R,
3. To render the final research report in Latex.

Please note that a OpenAI API Key is required to run the simulation study. The results of the simulation study are provided on [OSF](https://osf.io/4ebmk/files/osfstorage). 


## Replication of simulation study in Python

To be able to replicate the results of the simulation study, please follow the instructions below.

### Set-up

(1) Clone this repository.

(2) Download necessary files

Start by downloading the SYNERGY dataset from the following github page: [SYNERGY](https://github.com/asreview/synergy-dataset) and the inclusion criteria of all the synergy datasets from the OSF link provided above.

(3) Obtain an [OPENAI API key](https://openai.com/api/).

### Run the simulation study

The easiest way to replicate the simulation study, is by running the simulation within a virtual environment using the following steps.

Open a terminal and create a new virtual environment:
```
py -3.13 -m venv .venv
```

Activate the virtual environment:
```
.venv/Scrips/activate
```

Install the required Python dependencies:
```
pip install -r requirements.txt
```

Add your OpenAI API:
```
New-Item .env
$key = Read-Host 'Paste your OpenAI API key'
Set-Content -Path '.env' -NoNewline -Value ("OPEN_API_KEY='{0}'" -f $key)
Write-Host 'Done. Wrote OPEN_API_KEY to .env'
```

Once all the necessary files and python packages have been downloaded, run the following line in CLI in repository directory. 

```
python simulation_files\run.py 'path to synergy datasets' simulation_results\run_01 'path to inclusion criteria'
```

Please note that the resulting files may differ slightly from the results presented on OSF due to slightly different abstracts being generated by the large language models (LLMs). For 100% reproducibility the code would need to be slightly adjusted to accomodate the use of the abstracts and titles generated in the published simulation runs.  

## Replication of the statistical analysis in R

Open the R project file in your directory, Next, download all the necessary R packages.

```r
renv::restore()  
```

Finally, run the statistical analysis by knitting the R markdown file titled 'Markup_Assignment.Rmd'.

```r
rmarkdown::render("Analysis/R/Markup_Assignment.Rmd")
```

(Note that if the simulation results were downloaded from OSF directly, these should be stored as ../simulation_results/run_01/all_simulation_results.csv for the R markdown code to run smoothly.)

## Knitting the research report

After running the statistical analysis in R, compile the report using either:

- **VS Code**: open `Report/main.tex` and build with the _LaTeX Workshop_ extension.
- **Directly in CMD**:
```
latexmk -cd -pdf -shell-escape Report/main.tex
```

